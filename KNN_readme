K-Nearest Neighbors (KNN) Algorithm
K-Nearest Neighbors (KNN) is a simple, non-parametric, and versatile supervised learning algorithm used for both classification and regression. It works by finding the k closest data points (neighbors) to a given query point and making predictions based on those neighbors.
________________________________________
How KNN Works
1.	Data Storage:
o	KNN memorizes the entire training dataset, making it a lazy learner.
2.	Prediction:
o	For classification:
	Finds the k nearest neighbors using a distance metric (e.g., Euclidean distance).
	Assigns the majority class among the neighbors to the query point.
o	For regression:
	Averages the target values of the k neighbors.
3.	Distance Metrics:
o	Euclidean Distance: d=∑(xi−yi)2d = \sqrt{\sum (x_i - y_i)^2}d=∑(xi−yi)2
