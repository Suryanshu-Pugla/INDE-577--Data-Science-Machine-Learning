{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9809ZQo2uJ9Y/U7ix2vAB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suryanshu-Pugla/INDE-577--Data-Science-Machine-Learning/blob/main/Supervised%20Learning/6.1%20Decision%20Tree%20from%20Scartch/Decision_Tree_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1mnyoGOMpDb",
        "outputId": "cfa59b60-43c8-449e-9060-fb6996c83093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier Results on Breast Cancer Dataset:\n",
            "Accuracy: 0.95\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Define the Decision Tree Classifier\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=5, min_samples_split=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.tree = None\n",
        "\n",
        "    # Gini Impurity calculation\n",
        "    def gini_impurity(self, y):\n",
        "        classes, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / len(y)\n",
        "        gini = 1 - np.sum(probabilities ** 2)\n",
        "        return gini\n",
        "\n",
        "    # Split data into left and right subsets\n",
        "    def split_data(self, X_column, threshold):\n",
        "        left_mask = X_column <= threshold\n",
        "        right_mask = ~left_mask\n",
        "        return left_mask, right_mask\n",
        "\n",
        "    # Find the best split for a dataset\n",
        "    def best_split(self, X, y):\n",
        "        best_gini = float('inf')\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        for feature_idx in range(n_features):\n",
        "            X_column = X[:, feature_idx]\n",
        "            thresholds = np.unique(X_column)\n",
        "            for threshold in thresholds:\n",
        "                left_mask, right_mask = self.split_data(X_column, threshold)\n",
        "                if np.sum(left_mask) < self.min_samples_split or np.sum(right_mask) < self.min_samples_split:\n",
        "                    continue\n",
        "\n",
        "                # Calculate weighted Gini impurity\n",
        "                gini_left = self.gini_impurity(y[left_mask])\n",
        "                gini_right = self.gini_impurity(y[right_mask])\n",
        "                gini_total = (len(y[left_mask]) * gini_left + len(y[right_mask]) * gini_right) / len(y)\n",
        "\n",
        "                if gini_total < best_gini:\n",
        "                    best_gini = gini_total\n",
        "                    best_feature = feature_idx\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    # Recursive tree building\n",
        "    def build_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        # Stopping conditions\n",
        "        if depth >= self.max_depth or len(unique_classes) == 1 or num_samples < self.min_samples_split:\n",
        "            leaf_value = self.majority_class(y)\n",
        "            return {'leaf': True, 'value': leaf_value}\n",
        "\n",
        "        # Find the best split\n",
        "        feature_idx, threshold = self.best_split(X, y)\n",
        "        if feature_idx is None:\n",
        "            leaf_value = self.majority_class(y)\n",
        "            return {'leaf': True, 'value': leaf_value}\n",
        "\n",
        "        # Split the data\n",
        "        left_mask, right_mask = self.split_data(X[:, feature_idx], threshold)\n",
        "        left_tree = self.build_tree(X[left_mask], y[left_mask], depth + 1)\n",
        "        right_tree = self.build_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "\n",
        "        # Return the node\n",
        "        return {\n",
        "            'leaf': False,\n",
        "            'feature_idx': feature_idx,\n",
        "            'threshold': threshold,\n",
        "            'left': left_tree,\n",
        "            'right': right_tree\n",
        "        }\n",
        "\n",
        "    # Find the majority class\n",
        "    def majority_class(self, y):\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        return values[np.argmax(counts)]\n",
        "\n",
        "    # Train the decision tree\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self.build_tree(X, y)\n",
        "\n",
        "    # Predict for a single sample\n",
        "    def predict_sample(self, node, sample):\n",
        "        if node['leaf']:\n",
        "            return node['value']\n",
        "        if sample[node['feature_idx']] <= node['threshold']:\n",
        "            return self.predict_sample(node['left'], sample)\n",
        "        else:\n",
        "            return self.predict_sample(node['right'], sample)\n",
        "\n",
        "    # Predict for all samples\n",
        "    def predict(self, X):\n",
        "        return np.array([self.predict_sample(self.tree, sample) for sample in X])\n",
        "\n",
        "\n",
        "# Step 2: Load Breast Cancer Dataset\n",
        "data = load_breast_cancer()\n",
        "X = data['data']  # Feature matrix\n",
        "y = data['target']  # Target labels (0: Malignant, 1: Benign)\n",
        "\n",
        "# Step 3: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train the Decision Tree\n",
        "tree = DecisionTree(max_depth=5, min_samples_split=5)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Test and Evaluate the Model\n",
        "y_pred = tree.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Step 6: Print the Results\n",
        "print(\"Decision Tree Classifier Results on Breast Cancer Dataset:\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oarXKEHPM6AV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}